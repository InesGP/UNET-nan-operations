{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration to be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image:\n",
      "tensor([[[[ 1.,  2.,  3.,  4.],\n",
      "          [ 5.,  6.,  7.,  8.],\n",
      "          [ 9., 10., 11., 12.],\n",
      "          [13., 14., 15., 16.]]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 4x4 image tensor\n",
    "image = torch.arange(1, 17).reshape(1, 1, 4, 4).float()  # Shape: (N, C, H, W)\n",
    "print(\"Original Image:\")\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfolded Image Patches:\n",
      "tensor([[[[[[ 1.,  2.],\n",
      "            [ 5.,  6.]],\n",
      "\n",
      "           [[ 2.,  3.],\n",
      "            [ 6.,  7.]],\n",
      "\n",
      "           [[ 3.,  4.],\n",
      "            [ 7.,  8.]]],\n",
      "\n",
      "\n",
      "          [[[ 5.,  6.],\n",
      "            [ 9., 10.]],\n",
      "\n",
      "           [[ 6.,  7.],\n",
      "            [10., 11.]],\n",
      "\n",
      "           [[ 7.,  8.],\n",
      "            [11., 12.]]],\n",
      "\n",
      "\n",
      "          [[[ 9., 10.],\n",
      "            [13., 14.]],\n",
      "\n",
      "           [[10., 11.],\n",
      "            [14., 15.]],\n",
      "\n",
      "           [[11., 12.],\n",
      "            [15., 16.]]]]]])\n"
     ]
    }
   ],
   "source": [
    "# Unfold the tensor to extract 2x2 patches with a stride of 1\n",
    "patches = image.unfold(2, 2, 1).unfold(3, 2, 1)\n",
    "print(\"Unfolded Image Patches:\")\n",
    "print(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Image Patches (im2col format):\n",
      "tensor([[ 1.,  2.,  5.,  6.],\n",
      "        [ 2.,  3.,  6.,  7.],\n",
      "        [ 3.,  4.,  7.,  8.],\n",
      "        [ 5.,  6.,  9., 10.],\n",
      "        [ 6.,  7., 10., 11.],\n",
      "        [ 7.,  8., 11., 12.],\n",
      "        [ 9., 10., 13., 14.],\n",
      "        [10., 11., 14., 15.],\n",
      "        [11., 12., 15., 16.]])\n"
     ]
    }
   ],
   "source": [
    "# Reshape the unfolded tensor to get patches as columns\n",
    "patches = patches.contiguous().view(1, 1, -1, 2 * 2)  # Shape: (N, C, number_of_patches, patch_size)\n",
    "patches = patches.view(-1, 2 * 2)  # Shape: (N * C * number_of_patches, patch_size)\n",
    "print(\"Reshaped Image Patches (im2col format):\")\n",
    "print(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image:\n",
      "tensor([[[[ 1.,  2.,  3.,  4.],\n",
      "          [ 5.,  6.,  7.,  8.],\n",
      "          [ 9., 10., 11., 12.],\n",
      "          [13., 14., 15., 16.]]]])\n",
      "Unfolded Image Patches:\n",
      "tensor([[[[[[ 1.,  2.],\n",
      "            [ 5.,  6.]],\n",
      "\n",
      "           [[ 2.,  3.],\n",
      "            [ 6.,  7.]],\n",
      "\n",
      "           [[ 3.,  4.],\n",
      "            [ 7.,  8.]]],\n",
      "\n",
      "\n",
      "          [[[ 5.,  6.],\n",
      "            [ 9., 10.]],\n",
      "\n",
      "           [[ 6.,  7.],\n",
      "            [10., 11.]],\n",
      "\n",
      "           [[ 7.,  8.],\n",
      "            [11., 12.]]],\n",
      "\n",
      "\n",
      "          [[[ 9., 10.],\n",
      "            [13., 14.]],\n",
      "\n",
      "           [[10., 11.],\n",
      "            [14., 15.]],\n",
      "\n",
      "           [[11., 12.],\n",
      "            [15., 16.]]]]]])\n",
      "Reshaped Image Patches (im2col format):\n",
      "tensor([[ 1.,  2.,  5.,  6.],\n",
      "        [ 2.,  3.,  6.,  7.],\n",
      "        [ 3.,  4.,  7.,  8.],\n",
      "        [ 5.,  6.,  9., 10.],\n",
      "        [ 6.,  7., 10., 11.],\n",
      "        [ 7.,  8., 11., 12.],\n",
      "        [ 9., 10., 13., 14.],\n",
      "        [10., 11., 14., 15.],\n",
      "        [11., 12., 15., 16.]])\n",
      "Convolution Output:\n",
      "tensor([[[[-5., -5., -5.],\n",
      "          [-5., -5., -5.],\n",
      "          [-5., -5., -5.]]]])\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create the Input Tensor\n",
    "image = torch.arange(1, 17).reshape(1, 1, 4, 4).float()  # Shape: (N, C, H, W)\n",
    "print(\"Original Image:\")\n",
    "print(image)\n",
    "\n",
    "# Step 2: Use torch.unfold to extract 2x2 patches with a stride of 1\n",
    "patches = image.unfold(2, 2, 1).unfold(3, 2, 1)\n",
    "print(\"Unfolded Image Patches:\")\n",
    "print(patches)\n",
    "\n",
    "# Step 3: Reshape the Unfolded Tensor to im2col format\n",
    "patches = patches.contiguous().view(1, 1, -1, 2 * 2)  # Shape: (N, C, number_of_patches, patch_size)\n",
    "patches = patches.view(-1, 2 * 2)  # Shape: (N * C * number_of_patches, patch_size)\n",
    "print(\"Reshaped Image Patches (im2col format):\")\n",
    "print(patches)\n",
    "\n",
    "# Create a 2x2 convolution kernel\n",
    "kernel = torch.tensor([[1, 0], [0, -1]]).float().view(1, -1)  # Shape: (1, patch_size)\n",
    "\n",
    "# Perform convolution by matrix multiplication\n",
    "output = patches @ kernel.t()  # Shape: (number_of_patches, 1)\n",
    "output = output.view(1, 1, 3, 3)  # Shape: (N, C, H', W') where H' and W' are the output dimensions\n",
    "\n",
    "print(\"Convolution Output:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution Output:\n",
      "tensor([[[[-5., -5., -5.],\n",
      "          [-5., -5., -5.],\n",
      "          [-5., -5., -5.]]]])\n"
     ]
    }
   ],
   "source": [
    "def im2col_convolution(image, kernel, stride):\n",
    "\n",
    "    kernel_height = kernel.shape[0]\n",
    "    kernel_width = kernel.shape[1]    \n",
    "\n",
    "    # Unfold the image to extract patches with the given kernel size and stride\n",
    "    # First we unfold by dimension 2 (height) then dimension 3 (width)\n",
    "    patches = image.unfold(2, kernel_height, stride).unfold(3, kernel_width, stride)\n",
    "    \n",
    "    # Reshape the unfolded tensor to im2col format\n",
    "    # Also ensure tensor is in contiguous in memory format\n",
    "    patches = patches.contiguous().view(1, 1, -1, kernel_height * kernel_width)  # Shape: (N * C * number_of_patches, patch_size)\n",
    "\n",
    "    # Reshape the kernel to match the patch size\n",
    "    kernel = kernel.view(1, -1)  # Shape: (1, patch_size)\n",
    "\n",
    "    # Perform convolution by matrix multiplication\n",
    "    output = patches @ kernel.t()  # Shape: (number_of_patches, 1)\n",
    "\n",
    "    # Calculate output dimensions\n",
    "    output_height = (image.shape[2] - kernel_height) // stride + 1\n",
    "    output_width = (image.shape[3] - kernel_width) // stride + 1\n",
    "    output = output.view(1, 1, output_height, output_width)  # Shape: (N, C, H', W')\n",
    "\n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "image = torch.arange(1, 17).reshape(1, 1, 4, 4).float()  # Shape: (N, C, H, W)\n",
    "kernel = torch.tensor([[1, 0], [0, -1]]).float()  # Shape: (kernel_H, kernel_W)\n",
    "\n",
    "kernel_size = 2\n",
    "stride = 1\n",
    "\n",
    "output = im2col_convolution(image, kernel, stride)\n",
    "print(\"Convolution Output:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Python Convolution -- no NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution Output:\n",
      "tensor([[[[-15., -15., -15.],\n",
      "          [-15., -15., -15.],\n",
      "          [-15., -15., -15.]],\n",
      "\n",
      "         [[ -9.,  -9.,  -9.],\n",
      "          [ -9.,  -9.,  -9.],\n",
      "          [ -9.,  -9.,  -9.]]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#CURRENT LIMITATIONS: EXPECTS 4D input, cannot deal with 3D input\n",
    "def im2col_convolution(image, kernel, stride):\n",
    "    N, C, H, W = image.shape  # Get the shape of the input image\n",
    "    out_channels, in_channels, K_H, K_W = kernel.shape  # Get the shape of the kernel\n",
    "\n",
    "    assert C == in_channels, \"Number of input channels must match between image and kernel.\"\n",
    "\n",
    "    # Unfold the image to extract patches with the given kernel size and stride\n",
    "    patches = image.unfold(2, K_H, stride).unfold(3, K_W, stride)\n",
    "    # print(patches)\n",
    "    \n",
    "    # Calculate the number of patches\n",
    "    num_patches_h = patches.size(2)\n",
    "    num_patches_w = patches.size(3)\n",
    "    \n",
    "    # Reshape the unfolded tensor to im2col format\n",
    "    # Shape: (N, C, num_patches_h * num_patches_w, K_H * K_W)\n",
    "    patches = patches.contiguous().view(N, C, num_patches_h * num_patches_w, K_H * K_W)\n",
    "    # print(patches)\n",
    "\n",
    "    # Reshape the kernel to match the patch size\n",
    "    # Shape: (out_channels, in_channels, K_H * K_W)\n",
    "    kernel = kernel.view(out_channels, in_channels * K_H * K_W)\n",
    "\n",
    "    # Perform convolution by matrix multiplication\n",
    "    # Shape of patches: (N, C, num_patches_h * num_patches_w, K_H * K_W)\n",
    "    # Shape of kernel: (out_channels, in_channels * K_H * K_W)\n",
    "    # Need to multiply patches with kernel properly\n",
    "    # Reshape patches to (N * num_patches_h * num_patches_w, C * K_H * K_W)\n",
    "    patches_reshaped = patches.permute(0, 2, 1, 3).reshape(-1, in_channels * K_H * K_W)\n",
    "    kernel_reshaped = kernel.t()  # Shape: (in_channels * K_H * K_W, out_channels)\n",
    "\n",
    "    # Matrix multiplication to get the output\n",
    "    # Shape: (N * num_patches_h * num_patches_w, out_channels)\n",
    "    output_reshaped = torch.mm(patches_reshaped, kernel_reshaped)\n",
    "\n",
    "    # Reshape output to match the expected dimensions\n",
    "    # output_height = (H - K_H) // stride + 1\n",
    "    # output_width = (W - K_W) // stride + 1\n",
    "    output = output_reshaped.view(N, num_patches_h, num_patches_w, out_channels)\n",
    "    output = output.permute(0, 3, 1, 2)  # Shape: (N, out_channels, num_patches_h, num_patches_w)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "image = torch.arange(1, 49).reshape(1, 3, 4, 4).float()  # Shape: (N, C, H, W)\n",
    "kernel = torch.tensor([[[[1, 0], [0, -1]], [[1, 0], [0, -1]], [[1, 0], [0, -1]]],\n",
    "                       [[[0, 1], [-1, 0]], [[0, 1], [-1, 0]], [[0, 1], [-1, 0]]]]).float()  # Shape: (out_channels, in_channels, K_H, K_W)\n",
    "\n",
    "stride = 1\n",
    "\n",
    "output = im2col_convolution(image, kernel, stride)\n",
    "print(\"Convolution Output:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan, nan],\n",
      "          [nan, nan,  7.,  8.],\n",
      "          [ 9., nan, 11., 12.],\n",
      "          [nan, nan, 15., 16.]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0]]), tensor([[[ True, False, False, False]]]))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(image)\n",
    "nan_counts = torch.sum(image.isnan(), dim=3)\n",
    "    \n",
    "# Find the rows that exceed the threshold\n",
    "rows_to_extract = nan_counts/image.shape[3] > 0.5\n",
    "\n",
    "# Extract the rows and their positions\n",
    "extracted_rows = image[~rows_to_extract]\n",
    "extracted_rows = extracted_rows.view(*image.shape[:2], (~rows_to_extract).sum(), image.shape[-1])\n",
    "extracted_rows\n",
    "positions = torch.nonzero(rows_to_extract) #.squeeze()\n",
    "positions\n",
    "\n",
    "extracted_rows, extracted_rows.shape\n",
    "positions, rows_to_extract\n",
    "# extract_rows_with_nans(image, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan, nan],\n",
      "          [nan, nan,  7.,  8.],\n",
      "          [ 9., 10., nan, nan],\n",
      "          [nan, nan, nan, nan]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MaskedTensor(\n",
       "  [\n",
       "    [\n",
       "      [\n",
       "        [      --,       --,       --,       --],\n",
       "        [      --,       --,   7.0000,   8.0000],\n",
       "        [  9.0000,  10.0000,       --,       --],\n",
       "        [      --,       --,       --,       --]\n",
       "      ]\n",
       "    ]\n",
       "  ]\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.masked import masked_tensor, as_masked_tensor\n",
    "\n",
    "\n",
    "image[:, :, 0] = float('nan')\n",
    "image[:, :, 1, :2] = float('nan')\n",
    "image[:, :, 2, 2:] = float('nan')\n",
    "image[:, :, 3, :] = float('nan')\n",
    "print(image)\n",
    "\n",
    "\n",
    "mt = masked_tensor(image, ~torch.isnan(image))\n",
    "mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ine5/dynamo_env/lib/python3.10/site-packages/torch/masked/maskedtensor/core.py:156: UserWarning: The PyTorch API of MaskedTensors is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.masked module for further information about the project.\n",
      "  warnings.warn((\"The PyTorch API of MaskedTensors is in prototype stage \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(crow_indices=tensor([0, 0, 2, 4, 4]),\n",
       "       col_indices=tensor([2, 3, 0, 1]),\n",
       "       values=tensor([ 7.,  8.,  9., 10.]), size=(4, 4), nnz=4,\n",
       "       layout=torch.sparse_csr)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mt.shape)\n",
    "sparse_coo_mt = mt[0,0].to_sparse_csr()\n",
    "sparse_coo_mt.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan, nan],\n",
      "          [nan, nan,  7.,  8.],\n",
      "          [ 9., nan, 11., 12.],\n",
      "          [nan, nan, 15., 16.]]]])\n",
      "tensor([[[[nan, nan, nan, nan],\n",
      "          [nan, nan, nan,  7.],\n",
      "          [nan, nan,  7.,  8.],\n",
      "          [nan, nan,  9., nan],\n",
      "          [nan,  7., nan, 11.],\n",
      "          [ 7.,  8., 11., 12.],\n",
      "          [ 9., nan, nan, nan],\n",
      "          [nan, 11., nan, 15.],\n",
      "          [11., 12., 15., 16.]]]])\n",
      "tensor([[[[nan, nan,  7.,  8.],\n",
      "          [nan,  7., nan, 11.],\n",
      "          [ 7.,  8., 11., 12.],\n",
      "          [nan, 11., nan, 15.],\n",
      "          [11., 12., 15., 16.]]]])\n",
      "torch.Size([1, 5, 1, 4])\n",
      "torch.Size([4, 1])\n",
      "torch.Size([1, 5, 1, 1])\n",
      "torch.Size([1, 3, 3, 1])\n",
      "tensor([[0, 0, 2],\n",
      "        [0, 0, 4],\n",
      "        [0, 0, 5],\n",
      "        [0, 0, 7],\n",
      "        [0, 0, 8]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape mismatch: value tensor of shape [5, 1, 1] cannot be broadcast to indexing result of shape [5, 3, 3, 3, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(valid_positions)\n\u001b[0;32m---> 87\u001b[0m \u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalid_positions\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m output_reshaped\n\u001b[1;32m     88\u001b[0m output[nan_positions, :] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# output = output_reshaped.view(N, num_patches_h, num_patches_w, out_channels)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape mismatch: value tensor of shape [5, 1, 1] cannot be broadcast to indexing result of shape [5, 3, 3, 3, 1]"
     ]
    }
   ],
   "source": [
    "def extract_rows_with_nans(matrix, threshold):\n",
    "    # Count the number of NaNs in each row\n",
    "    nan_counts = torch.sum(matrix.isnan(), dim=3)\n",
    "    \n",
    "    # Find the rows that exceed the threshold\n",
    "    rows_to_extract = nan_counts/matrix.shape[3] > threshold\n",
    "    \n",
    "    # Extract the rows and their positions\n",
    "    # REPLACE NANS?\n",
    "    extracted_rows = matrix[~rows_to_extract]\n",
    "    extracted_rows = extracted_rows.view(*image.shape[:2], (~rows_to_extract).sum(), image.shape[-1])\n",
    "\n",
    "    nan_positions = torch.nonzero(rows_to_extract).squeeze()\n",
    "    valid_positions = torch.nonzero(~rows_to_extract).squeeze()\n",
    "\n",
    "    return extracted_rows, nan_positions, valid_positions\n",
    "\n",
    "\n",
    "image = torch.arange(1, 17).reshape(1, 1, 4, 4).float()  # Shape: (N, C, H, W)\n",
    "image[:, :, 0] = float('nan')\n",
    "image[:, :, 1, :2] = float('nan')\n",
    "image[:, :, 2, 1] = float('nan')\n",
    "image[:, :, 3, :2] = float('nan')\n",
    "\n",
    "kernel = torch.tensor([[[[1, 0], [0, -1]], [[1, 0], [0, -1]], [[1, 0], [0, -1]]],\n",
    "                       [[[0, 1], [-1, 0]], [[0, 1], [-1, 0]], [[0, 1], [-1, 0]]]]).float()  # Shape: (out_channels, in_channels, K_H, K_W)\n",
    "\n",
    "# kernel = torch.tensor([[1, 0], [0, -1]]).float().view(1, 1, 1, -1)  # Shape: (1, patch_size)\n",
    "kernel = torch.randn(1, 1, 2, 2)  # Shape: (out_channels, in_channels, kernel_height, kernel_width)\n",
    "print(image)\n",
    "stride = 1\n",
    "\n",
    "# output = im2col_convolution(image, kernel, stride)\n",
    "# print(\"Convolution Output:\")\n",
    "# print(output)\n",
    "\n",
    "\n",
    "N, C, H, W = image.shape  # Get the shape of the input image\n",
    "out_channels, in_channels, K_H, K_W = kernel.shape  # Get the shape of the kernel\n",
    "\n",
    "assert C == in_channels, \"Number of input channels must match between image and kernel.\"\n",
    "\n",
    "# Unfold the image to extract patches with the given kernel size and stride\n",
    "patches = image.unfold(2, K_H, stride).unfold(3, K_W, stride)\n",
    "# print(patches)\n",
    "\n",
    "# Calculate the number of patches\n",
    "num_patches_h = patches.size(2)\n",
    "num_patches_w = patches.size(3)\n",
    "\n",
    "# Reshape the unfolded tensor to im2col format\n",
    "# Shape: (N, C, num_patches_h * num_patches_w, K_H * K_W)\n",
    "patches = patches.contiguous().view(N, C, num_patches_h * num_patches_w, K_H * K_W)\n",
    "print(patches)\n",
    "\n",
    "patches, nan_positions, valid_positions = extract_rows_with_nans(patches, 0.5)\n",
    "\n",
    "print(patches)\n",
    "\n",
    "# Reshape the kernel to match the patch size\n",
    "# Shape: (out_channels, in_channels, K_H * K_W)\n",
    "kernel = kernel.view(out_channels, in_channels * K_H * K_W)\n",
    "\n",
    "# Perform convolution by matrix multiplication\n",
    "# Shape of patches: (N, C, num_patches_h * num_patches_w, K_H * K_W)\n",
    "# Shape of kernel: (out_channels, in_channels * K_H * K_W)\n",
    "# Need to multiply patches with kernel properly\n",
    "# Reshape patches to (N * num_patches_h * num_patches_w, C * K_H * K_W)\n",
    "patches_reshaped = patches.permute(0, 2, 1, 3) #.reshape(-1, in_channels * K_H * K_W)\n",
    "print(patches_reshaped.shape)\n",
    "kernel_reshaped = kernel.t()  # Shape: (in_channels * K_H * K_W, out_channels)\n",
    "print(kernel_reshaped.shape)\n",
    "\n",
    "# Matrix multiplication to get the output\n",
    "# Shape: (N * num_patches_h * num_patches_w, out_channels)\n",
    "output_reshaped = torch.matmul(patches_reshaped, kernel_reshaped)\n",
    "\n",
    "print(output_reshaped.shape)\n",
    "# print(positions)\n",
    "\n",
    "# Reshape output to match the expected dimensions\n",
    "# output_height = (H - K_H) // stride + 1\n",
    "# output_width = (W - K_W) // stride + 1\n",
    "output = torch.zeros(N, num_patches_h, num_patches_w, out_channels)\n",
    "print(output.shape)\n",
    "print(valid_positions)\n",
    "output[valid_positions] = output_reshaped\n",
    "output[nan_positions, :] = float('nan')\n",
    "\n",
    "# output = output_reshaped.view(N, num_patches_h, num_patches_w, out_channels)\n",
    "output = output.permute(0, 3, 1, 2)  # Shape: (N, out_channels, num_patches_h, num_patches_w)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2, 2])\n",
      "torch.Size([3, 3, 2, 2])\n",
      "Modified Matrix:\n",
      "tensor([[[[  1.,   2.],\n",
      "          [  3.,   4.]],\n",
      "\n",
      "         [[  5.,   6.],\n",
      "          [  7.,   8.]],\n",
      "\n",
      "         [[  9.,  10.],\n",
      "          [ 11.,  12.]]],\n",
      "\n",
      "\n",
      "        [[[130., 140.],\n",
      "          [150., 160.]],\n",
      "\n",
      "         [[170., 180.],\n",
      "          [190., 200.]],\n",
      "\n",
      "         [[210., 220.],\n",
      "          [230., 240.]]],\n",
      "\n",
      "\n",
      "        [[[250., 260.],\n",
      "          [270., 280.]],\n",
      "\n",
      "         [[290., 300.],\n",
      "          [310., 320.]],\n",
      "\n",
      "         [[330., 340.],\n",
      "          [350., 360.]]],\n",
      "\n",
      "\n",
      "        [[[370., 380.],\n",
      "          [390., 400.]],\n",
      "\n",
      "         [[410., 420.],\n",
      "          [430., 440.]],\n",
      "\n",
      "         [[450., 460.],\n",
      "          [470., 480.]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2, 2])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a 4D tensor\n",
    "matrix = torch.tensor([\n",
    "    [[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]],\n",
    "    [[[13, 14], [15, 16]], [[17, 18], [19, 20]], [[21, 22], [23, 24]]],\n",
    "    [[[25, 26], [27, 28]], [[29, 30], [31, 32]], [[33, 34], [35, 36]]],\n",
    "    [[[37, 38], [39, 40]], [[41, 42], [43, 44]], [[45, 46], [47, 48]]]\n",
    "], dtype=torch.float32)\n",
    "print(matrix.shape)\n",
    "\n",
    "# Define a condition to select certain rows\n",
    "threshold = 40\n",
    "condition = torch.sum(matrix[:, 0, :, :], dim=(1, 2)) > threshold\n",
    "\n",
    "# Get the indices of the rows that meet the condition\n",
    "indices = torch.nonzero(condition).squeeze()\n",
    "\n",
    "# Modify the selected rows (for demonstration purposes, we'll just multiply them by 10)\n",
    "modified_rows = matrix[indices] * 10\n",
    "print(modified_rows.shape)\n",
    "\n",
    "# Create a new tensor to hold the modified data\n",
    "new_matrix = matrix.clone()\n",
    "\n",
    "# Reinsert the modified rows back into their original positions\n",
    "new_matrix[indices] = modified_rows\n",
    "\n",
    "print(\"Modified Matrix:\")\n",
    "print(new_matrix)\n",
    "new_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expansion to automatically adjust to 3D or 4D input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4, 4])\n",
      "Convolution Output:\n",
      "tensor([[[[-15., -15., -15.],\n",
      "          [-15., -15., -15.],\n",
      "          [-15., -15., -15.]],\n",
      "\n",
      "         [[ -9.,  -9.,  -9.],\n",
      "          [ -9.,  -9.,  -9.],\n",
      "          [ -9.,  -9.,  -9.]]]])\n",
      "torch.Size([1, 1, 4, 4])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m image_3d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m17\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# Shape: (N, C, H, W)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m kernel_3d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[[[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]]])\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# Shape: (out_channels, in_channels, K_H, K_W)\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m output_3d \u001b[38;5;241m=\u001b[39m \u001b[43mim2col_convolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_3d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_3d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvolution Output for 3D kernel and image:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(output_3d)\n",
      "Cell \u001b[0;32mIn[69], line 12\u001b[0m, in \u001b[0;36mim2col_convolution\u001b[0;34m(image, kernel, stride)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m N, C, H, W \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape  \u001b[38;5;66;03m# Get the shape of the input image\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m out_channels, in_channels, K_H, K_W \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mshape  \u001b[38;5;66;03m# Get the shape of the kernel\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m C \u001b[38;5;241m==\u001b[39m in_channels, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of input channels must match between image and kernel.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Unfold the image to extract patches with the given kernel size and stride\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "\n",
    "def im2col_convolution(image, kernel, stride):\n",
    "    if image.dim() == 3:  # Handle 3D image case (single-channel, no batch)\n",
    "        image = image.unsqueeze(0) #.unsqueeze(0)  # Add batch and channel dimensions\n",
    "        kernel = kernel.unsqueeze(0)  # Add batch dimension to kernel\n",
    "\n",
    "    if kernel.dim() == 3:  # Handle 3D kernel case (single channel, no batch)\n",
    "        kernel = kernel.unsqueeze(0)  # Add batch dimension to kernel\n",
    "\n",
    "    print(image.shape)\n",
    "\n",
    "    N, C, H, W = image.shape  # Get the shape of the input image\n",
    "    out_channels, in_channels, K_H, K_W = kernel.shape  # Get the shape of the kernel\n",
    "\n",
    "    assert C == in_channels, \"Number of input channels must match between image and kernel.\"\n",
    "\n",
    "    # Unfold the image to extract patches with the given kernel size and stride\n",
    "    patches = image.unfold(2, K_H, stride).unfold(3, K_W, stride)\n",
    "    \n",
    "    # Calculate the number of patches\n",
    "    num_patches_h = patches.size(2)\n",
    "    num_patches_w = patches.size(3)\n",
    "    \n",
    "    # Reshape the unfolded tensor to im2col format\n",
    "    patches = patches.contiguous().view(N, C, num_patches_h * num_patches_w, K_H * K_W)\n",
    "\n",
    "    # Reshape the kernel to match the patch size\n",
    "    kernel = kernel.view(out_channels, in_channels * K_H * K_W)\n",
    "\n",
    "    # Perform convolution by matrix multiplication\n",
    "    patches_reshaped = patches.permute(0, 2, 1, 3).reshape(-1, in_channels * K_H * K_W)\n",
    "    kernel_reshaped = kernel.t()  # Shape: (in_channels * K_H * K_W, out_channels)\n",
    "\n",
    "    # Matrix multiplication to get the output\n",
    "    output_reshaped = torch.mm(patches_reshaped, kernel_reshaped)\n",
    "\n",
    "    # Reshape output to match the expected dimensions\n",
    "    output_height = (H - K_H) // stride + 1\n",
    "    output_width = (W - K_W) // stride + 1\n",
    "    output = output_reshaped.view(N, num_patches_h, num_patches_w, out_channels)\n",
    "    output = output.permute(0, 3, 1, 2)  # Shape: (N, out_channels, num_patches_h, num_patches_w)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "image_4d = torch.arange(1, 49).reshape(1, 3, 4, 4).float()  # Shape: (N, C, H, W)\n",
    "kernel_4d = torch.tensor([[[[1, 0], [0, -1]], [[1, 0], [0, -1]], [[1, 0], [0, -1]]],\n",
    "                          [[[0, 1], [-1, 0]], [[0, 1], [-1, 0]], [[0, 1], [-1, 0]]]]).float()  # Shape: (out_channels, in_channels, K_H, K_W)\n",
    "\n",
    "stride = 1\n",
    "\n",
    "output = im2col_convolution(image_4d, kernel_4d, stride)\n",
    "print(\"Convolution Output:\")\n",
    "print(output)\n",
    "\n",
    "# Example for 3D kernel and image\n",
    "image_3d = torch.arange(1, 17).reshape(1, 4, 4).float()  # Shape: (N, C, H, W)\n",
    "kernel_3d = torch.tensor([[[[1, 0], [0, -1]]]]).float()  # Shape: (out_channels, in_channels, K_H, K_W)\n",
    "\n",
    "output_3d = im2col_convolution(image_3d, kernel_3d, stride)\n",
    "print(\"Convolution Output for 3D kernel and image:\")\n",
    "print(output_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-5., -5., -5.],\n",
       "          [-5., -5., -5.],\n",
       "          [-5., -5., -5.]]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.conv2d(input=image_3d, weight=kernel_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 4])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_3d.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
